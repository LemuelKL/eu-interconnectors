{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook converts tabular data to graph data for pytorch geometric to ingest.\n",
    "\n",
    "The final graph is a static homogeneous directed graph with temporal signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn import BatchNorm1d\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_df = pd.read_csv(\"data/flow/_combined.csv\")\n",
    "dap_df = pd.read_csv(\"data/dap/_combined.csv\")\n",
    "flow_df.set_index(\"datetime\", inplace=True)\n",
    "dap_df.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "datetime_intersect = flow_df.index.intersection(dap_df.index)\n",
    "flow_df = flow_df.loc[datetime_intersect]\n",
    "dap_df = dap_df.loc[datetime_intersect]\n",
    "\n",
    "# Remove columns that contains \"UK\" or \"IE\"\n",
    "flow_df = flow_df.loc[\n",
    "    :, ~flow_df.columns.str.contains(\"UK\") & ~flow_df.columns.str.contains(\"IE\")\n",
    "]\n",
    "dap_df = dap_df.loc[\n",
    "    :, ~dap_df.columns.str.contains(\"UK\") & ~dap_df.columns.str.contains(\"IE\")\n",
    "]\n",
    "\n",
    "# print(flow_df.isnull().sum())\n",
    "# print(dap_df.isnull().sum())\n",
    "assert not flow_df.isnull().values.any()\n",
    "assert not dap_df.isnull().values.any()\n",
    "dap_df = dap_df.reindex(sorted(dap_df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             BE->DE    BE->FR    BE->LU    BE->NL    DE->BE  \\\n",
      "datetime                                                                      \n",
      "2023-04-01 00:00:00+00:00 -0.891149 -0.470883 -0.094801  2.616577 -0.541081   \n",
      "2023-04-01 01:00:00+00:00 -0.944479 -0.470883  0.750963  3.598008  2.448207   \n",
      "2023-04-01 02:00:00+00:00 -0.944479 -0.470883  1.302386  2.919569  1.663773   \n",
      "2023-04-01 03:00:00+00:00 -0.944479 -0.470883  0.654091  1.892031  0.741433   \n",
      "2023-04-01 04:00:00+00:00 -0.944479 -0.470883 -0.780355  0.269487  0.050287   \n",
      "\n",
      "                             DE->DK    DE->AT    DE->CH    DE->CZ    DE->FR  \\\n",
      "datetime                                                                      \n",
      "2023-04-01 00:00:00+00:00 -0.375745  0.765371  0.384475  0.277879 -0.400487   \n",
      "2023-04-01 01:00:00+00:00 -0.375745  0.680750  0.178445  0.445536 -0.400487   \n",
      "2023-04-01 02:00:00+00:00 -0.375745  0.769439  0.375343  0.440351 -0.400487   \n",
      "2023-04-01 03:00:00+00:00 -0.370642  0.873589  0.411142  0.443807 -0.400487   \n",
      "2023-04-01 04:00:00+00:00 -0.244077  1.188477  0.631419  0.868998 -0.400487   \n",
      "\n",
      "                           ...    SE->DE    SE->NO    AT->DE    CH->DE  \\\n",
      "datetime                   ...                                           \n",
      "2023-04-01 00:00:00+00:00  ...  0.808136  2.069002 -1.177564 -0.863783   \n",
      "2023-04-01 01:00:00+00:00  ...  0.808136  2.276423 -0.994428 -0.672859   \n",
      "2023-04-01 02:00:00+00:00  ... -0.361820  2.381398 -0.972452 -0.700854   \n",
      "2023-04-01 03:00:00+00:00  ... -1.444692  2.657116 -0.992963 -0.760762   \n",
      "2023-04-01 04:00:00+00:00  ... -1.527990  2.869596 -1.226645 -0.872182   \n",
      "\n",
      "                             CH->FR    CZ->DE    PL->DE    ES->FR    IT->FR  \\\n",
      "datetime                                                                      \n",
      "2023-04-01 00:00:00+00:00 -0.496624 -0.561975 -0.386668  0.574449 -0.087357   \n",
      "2023-04-01 01:00:00+00:00 -0.496624 -0.657998 -0.386668  0.539312 -0.087357   \n",
      "2023-04-01 02:00:00+00:00 -0.496624 -0.597780 -0.386668  0.535738 -0.087357   \n",
      "2023-04-01 03:00:00+00:00 -0.496624 -0.508267 -0.386668  0.434197 -0.087357   \n",
      "2023-04-01 04:00:00+00:00 -0.496624 -0.550582 -0.386668  0.143570 -0.087357   \n",
      "\n",
      "                             FI->NO  \n",
      "datetime                             \n",
      "2023-04-01 00:00:00+00:00 -0.228901  \n",
      "2023-04-01 01:00:00+00:00 -0.228901  \n",
      "2023-04-01 02:00:00+00:00 -0.228901  \n",
      "2023-04-01 03:00:00+00:00 -0.228901  \n",
      "2023-04-01 04:00:00+00:00 -0.228901  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "                                 AT        BE        CH        CZ        DE  \\\n",
      "datetime                                                                      \n",
      "2023-04-01 00:00:00+00:00 -1.026846 -0.902024  0.100539 -1.028951 -0.826744   \n",
      "2023-04-01 01:00:00+00:00 -1.377537 -1.141419  0.105500 -1.393943 -1.161339   \n",
      "2023-04-01 02:00:00+00:00 -1.445183 -1.221723  0.065500 -1.462237 -1.223309   \n",
      "2023-04-01 03:00:00+00:00 -1.442385 -1.147245 -0.036206 -1.467043 -1.239359   \n",
      "2023-04-01 04:00:00+00:00 -1.491467 -1.189297  0.009065 -1.500431 -1.260982   \n",
      "\n",
      "                                 DK        ES        FI        FR        IT  \\\n",
      "datetime                                                                      \n",
      "2023-04-01 00:00:00+00:00 -0.868100 -1.069932 -0.162453 -0.918223  0.207948   \n",
      "2023-04-01 01:00:00+00:00 -0.856339 -1.277464 -0.150940 -1.223082 -0.384903   \n",
      "2023-04-01 02:00:00+00:00 -0.863270 -1.361860 -0.157725 -1.305076 -0.559365   \n",
      "2023-04-01 03:00:00+00:00 -0.860330 -1.393128 -0.154847 -1.335455 -0.210442   \n",
      "2023-04-01 04:00:00+00:00 -0.880701 -1.277464 -0.174789 -1.223082  0.364646   \n",
      "\n",
      "                                 LU        NL        NO        PL        SE  \n",
      "datetime                                                                     \n",
      "2023-04-01 00:00:00+00:00 -0.826744 -0.721657  0.991681  0.430200 -0.387022  \n",
      "2023-04-01 01:00:00+00:00 -1.161339 -0.718538  0.995245  0.438853 -0.374770  \n",
      "2023-04-01 02:00:00+00:00 -1.223309 -0.697332  1.021835  0.437700 -0.381990  \n",
      "2023-04-01 03:00:00+00:00 -1.239359 -0.385683  1.043490  0.440296 -0.378927  \n",
      "2023-04-01 04:00:00+00:00 -1.260982 -0.165721  1.083512  0.439142 -0.400150  \n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "# is this good enough?\n",
    "flow_df = (flow_df - flow_df.mean()) / flow_df.std()\n",
    "dap_df = (dap_df - dap_df.mean()) / dap_df.std()\n",
    "\n",
    "# print(flow_df.head())\n",
    "# print(dap_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 45)\n",
      "[['BE' 'BE' 'BE' 'DE' 'DE' 'DE' 'DE' 'DE' 'DE' 'DE']\n",
      " ['FR' 'LU' 'NL' 'BE' 'DK' 'AT' 'CH' 'CZ' 'FR' 'LU']]\n"
     ]
    }
   ],
   "source": [
    "# Static edges of shape (2, n_edges)\n",
    "interconnectors = flow_df.columns[1:]\n",
    "exporters = []\n",
    "importers = []\n",
    "for ic in interconnectors:\n",
    "    exporter, importer = ic.split(\"->\")\n",
    "    exporters.append(exporter)\n",
    "    importers.append(importer)\n",
    "\n",
    "exporters = np.array(exporters)\n",
    "importers = np.array(importers)\n",
    "\n",
    "edges = np.vstack([exporters, importers])\n",
    "print(edges.shape)\n",
    "print(edges[:, :10])\n",
    "n_edges = edges.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5136, 2, 45)\n"
     ]
    }
   ],
   "source": [
    "# Map edge names to indices\n",
    "edge_names = np.unique(edges)\n",
    "edge_map = {edge: i for i, edge in enumerate(edge_names)}\n",
    "edge_indices = np.array([edge_map[edge] for edge in edges.flatten()]).reshape(\n",
    "    edges.shape\n",
    ")\n",
    "# Repeat edge indices for each datetime\n",
    "edge_indices = np.repeat(\n",
    "    edge_indices[np.newaxis, :, :],\n",
    "    len(datetime_intersect),\n",
    "    axis=0,\n",
    ")\n",
    "print(edge_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5136, 45, 1)\n"
     ]
    }
   ],
   "source": [
    "# Edge labels (flow) of shape (n_datetimes, n_edges, 1)\n",
    "edge_labels = np.array(flow_df[interconnectors])\n",
    "edge_labels = np.reshape(edge_labels, (edge_labels.shape[0], edge_labels.shape[1], 1))\n",
    "print(edge_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5136, 45, 1)\n"
     ]
    }
   ],
   "source": [
    "# Edge attributes (capacity, etc.) of shape (n_datetimes, n_edges, n_attributes)\n",
    "# copy the edge labels to the edge attributes\n",
    "edge_attributes = np.copy(edge_labels)\n",
    "# hard code the edge attributes to be ones for now\n",
    "edge_attributes = np.ones(edge_labels.shape)\n",
    "print(edge_attributes.shape)\n",
    "# print(edge_attributes[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5136, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "# Node features (dap)\n",
    "node_features = np.array(node_features)\n",
    "node_features = np.reshape(\n",
    "    node_features, (node_features.shape[0], node_features.shape[1], 1)\n",
    ")\n",
    "print(node_features.shape)\n",
    "n_nodes = node_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge indices: (2, 45)\n",
      "Edge attributes: (45, 1)\n",
      "Edge labels: (45, 1)\n",
      "Node features: (15, 1)\n"
     ]
    }
   ],
   "source": [
    "assert (\n",
    "    len(datetime_intersect)\n",
    "    == edge_indices.shape[0]\n",
    "    == edge_attributes.shape[0]\n",
    "    == edge_labels.shape[0]\n",
    "    == node_features.shape[0]\n",
    ")\n",
    "# Print a snapshot of the shape of the graph data\n",
    "i = 256\n",
    "print(\"Edge indices:\", edge_indices[i].shape)\n",
    "print(\"Edge attributes:\", edge_attributes[i].shape)\n",
    "print(\"Edge labels:\", edge_labels[i].shape)\n",
    "print(\"Node features:\", node_features[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[15, 1], edge_index=[2, 45], edge_attr=[45, 1], y=[45, 1])\n"
     ]
    }
   ],
   "source": [
    "n_snapshots = len(datetime_intersect)\n",
    "snapshots = []\n",
    "for i in range(n_snapshots):\n",
    "    data = Data(\n",
    "        x=torch.tensor(node_features[i], dtype=torch.float),\n",
    "        edge_index=torch.tensor(edge_indices[i], dtype=torch.long),\n",
    "        edge_attr=torch.tensor(edge_attributes[i], dtype=torch.float),\n",
    "        y=torch.tensor(edge_labels[i], dtype=torch.float),\n",
    "    )\n",
    "    snapshots.append(data)\n",
    "print(snapshots[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GATv2Conv.html\n",
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, hidden_channels, num_heads_GAT, dropout_p_GAT, edge_dim_GAT, momentum_GAT\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.gat = GATv2Conv(\n",
    "            (-1, -1),\n",
    "            hidden_channels,\n",
    "            add_self_loops=False,\n",
    "            heads=num_heads_GAT,\n",
    "            edge_dim=edge_dim_GAT,\n",
    "        )\n",
    "        self.norm = BatchNorm1d(\n",
    "            hidden_channels,\n",
    "            momentum=momentum_GAT,\n",
    "            affine=False,\n",
    "            track_running_stats=False,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_p_GAT)\n",
    "\n",
    "    def forward(self, x, edge_indices, edge_attrs):\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm(x)\n",
    "        nodes_embedds = self.gat(x, edge_indices, edge_attrs)\n",
    "        nodes_embedds = F.leaky_relu(nodes_embedds, negative_slope=0.1)\n",
    "        return nodes_embedds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 16])\n"
     ]
    }
   ],
   "source": [
    "# Test GNNEncoder\n",
    "hidden_channels = 8\n",
    "num_heads_GAT = 2\n",
    "dropout_p_GAT = 0.1\n",
    "edge_dim_GAT = 1  # edge attributes\n",
    "momentum_GAT = 0.1\n",
    "encoder = GNNEncoder(\n",
    "    hidden_channels, num_heads_GAT, dropout_p_GAT, edge_dim_GAT, momentum_GAT\n",
    ")\n",
    "\n",
    "# Test forward pass\n",
    "i = 0\n",
    "x = snapshots[i].x\n",
    "edge_indices = snapshots[i].edge_index\n",
    "edge_attrs = snapshots[i].edge_attr\n",
    "\n",
    "nodes_embedds = encoder(x, edge_indices, edge_attrs)\n",
    "print(nodes_embedds.shape)\n",
    "# print(nodes_embedds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based module for creating temporal node embeddings.\n",
    "\n",
    "    Args:\n",
    "        dim_model (int): The dimension of the model's hidden states.\n",
    "        num_heads_TR (int): The number of attention heads.\n",
    "        num_encoder_layers_TR (int): The number of encoder layers.\n",
    "        num_decoder_layers_TR (int): The number of decoder layers.\n",
    "        dropout_p_TR (float): Dropout probability.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_model,\n",
    "        num_heads_TR,\n",
    "        num_encoder_layers_TR,\n",
    "        num_decoder_layers_TR,\n",
    "        dropout_p_TR,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pos_encoder = PositionalEncoding(dim_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=dim_model,\n",
    "            nhead=num_heads_TR,\n",
    "            num_decoder_layers=num_encoder_layers_TR,\n",
    "            num_encoder_layers=num_decoder_layers_TR,\n",
    "            dropout=dropout_p_TR,\n",
    "        )\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src = self.pos_encoder(src)\n",
    "        trg = self.pos_encoder(trg)\n",
    "        temporal_node_embeddings = self.transformer(src, trg)\n",
    "        return temporal_node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 15, 16])\n",
      "torch.Size([1, 15, 16])\n",
      "torch.Size([15, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Test Transformer\n",
    "num_heads_TR = 2\n",
    "num_encoder_layers_TR = 2\n",
    "num_decoder_layers_TR = 2\n",
    "dropout_p_TR = 0.1\n",
    "transformer = Transformer(\n",
    "    hidden_channels * num_heads_GAT,\n",
    "    num_heads_TR,\n",
    "    num_encoder_layers_TR,\n",
    "    num_decoder_layers_TR,\n",
    "    dropout_p_TR,\n",
    ")\n",
    "\n",
    "# Test forward pass\n",
    "seq_len = 24\n",
    "src_embedds = []\n",
    "for i in range(seq_len):\n",
    "    snapshot = snapshots[i]\n",
    "    src_embedds.append(encoder(snapshot.x, snapshot.edge_index, snapshot.edge_attr))\n",
    "src_embedds = torch.stack(src_embedds)\n",
    "trg_embedds = src_embedds[-1].unsqueeze(0)\n",
    "print(src_embedds.shape)\n",
    "print(trg_embedds.shape)\n",
    "\n",
    "temporal_node_embedds = transformer(src_embedds, trg_embedds)\n",
    "temporal_node_embedds = temporal_node_embedds.squeeze(0)\n",
    "print(temporal_node_embedds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeDecoder(nn.Module):\n",
    "    def __init__(self, hidden_channels, num_heads_GAT, num_edges, num_nodes):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(\n",
    "            num_nodes * hidden_channels * num_heads_GAT, hidden_channels\n",
    "        )\n",
    "        self.lin2 = nn.Linear(hidden_channels, num_edges)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the tensor\n",
    "        x = torch.flatten(x)\n",
    "        x = self.lin1(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.1)\n",
    "        x = self.lin2(x)\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 2 45\n",
      "torch.Size([45])\n"
     ]
    }
   ],
   "source": [
    "# Test EdgeDecoder\n",
    "print(hidden_channels, num_heads_GAT, n_edges)\n",
    "decoder = EdgeDecoder(hidden_channels, num_heads_GAT, n_edges, n_nodes)\n",
    "\n",
    "# Test forward pass\n",
    "edge_predictions = decoder(temporal_node_embedds)\n",
    "print(edge_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels,\n",
    "        num_heads_GAT,\n",
    "        dropout_p_GAT,\n",
    "        edge_dim_GAT,\n",
    "        momentum_GAT,\n",
    "        dim_model,\n",
    "        num_heads_TR,\n",
    "        num_encoder_layers_TR,\n",
    "        num_decoder_layers_TR,\n",
    "        dropout_p_TR,\n",
    "        num_edges,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(\n",
    "            hidden_channels, num_heads_GAT, dropout_p_GAT, edge_dim_GAT, momentum_GAT\n",
    "        )\n",
    "        self.transformer = Transformer(\n",
    "            dim_model,\n",
    "            num_heads_TR,\n",
    "            num_encoder_layers_TR,\n",
    "            num_decoder_layers_TR,\n",
    "            dropout_p_TR,\n",
    "        )\n",
    "        self.decoder = EdgeDecoder(hidden_channels, num_heads_GAT, num_edges, n_nodes)\n",
    "\n",
    "    def forward(self, x, edge_indices, edge_attrs):\n",
    "        src_embedds = []\n",
    "        for i in range(x.shape[0]):\n",
    "            src_embedds.append(self.encoder(x[i], edge_indices[i], edge_attrs[i]))\n",
    "        src_embedds = torch.stack(src_embedds)\n",
    "        trg_embedds = src_embedds[-1].unsqueeze(0)\n",
    "        temporal_node_embedds = self.transformer(src_embedds, trg_embedds)\n",
    "        temporal_node_embedds = temporal_node_embedds.squeeze(0)\n",
    "        edge_predictions = self.decoder(temporal_node_embedds)\n",
    "        return edge_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model(\n",
    "    hidden_channels,\n",
    "    num_heads_GAT,\n",
    "    dropout_p_GAT,\n",
    "    edge_dim_GAT,\n",
    "    momentum_GAT,\n",
    "    hidden_channels * num_heads_GAT,\n",
    "    num_heads_TR,\n",
    "    num_encoder_layers_TR,\n",
    "    num_decoder_layers_TR,\n",
    "    dropout_p_TR,\n",
    "    n_edges,\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4968 [00:00<19:03,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.2342640161514282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 102/4968 [00:21<16:20,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8182895183563232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 201/4968 [00:41<15:57,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8691268563270569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 302/4968 [01:01<15:42,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8302033543586731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 402/4968 [01:22<15:19,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5905413627624512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 502/4968 [01:42<15:07,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5877428650856018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 602/4968 [02:03<14:44,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5930600166320801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 702/4968 [02:23<14:20,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7041400074958801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 802/4968 [02:44<14:04,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4931166172027588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 902/4968 [03:04<13:45,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6004807353019714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1002/4968 [03:24<13:20,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3341328501701355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1102/4968 [03:45<13:16,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5179334282875061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1202/4968 [04:06<12:50,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6790197491645813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1302/4968 [04:26<12:48,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5504294037818909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1402/4968 [04:47<12:12,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7634257078170776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1502/4968 [05:08<11:52,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.6626137495040894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1602/4968 [05:28<11:36,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5621646046638489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1701/4968 [05:49<11:03,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1738470792770386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 1802/4968 [06:10<10:53,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5344696044921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1901/4968 [06:31<10:31,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5312365889549255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2001/4968 [06:52<10:07,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6128056049346924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2102/4968 [07:13<10:03,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.5386993885040283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 2201/4968 [07:34<10:13,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5528126955032349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 2301/4968 [07:55<09:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.535499095916748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2402/4968 [08:16<08:54,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6852515339851379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2502/4968 [08:37<08:30,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.883474588394165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2602/4968 [08:58<08:02,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4097172021865845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 2702/4968 [09:19<07:54,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.7587591409683228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 2801/4968 [09:40<07:23,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.46981650590896606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2902/4968 [10:01<07:05,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3054120540618896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3002/4968 [10:21<06:49,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8392885327339172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 3102/4968 [10:42<06:28,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.013670802116394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 3202/4968 [11:03<06:05,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.45886194705963135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 3302/4968 [11:24<05:56,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9480093717575073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3401/4968 [11:45<05:26,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5693511366844177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3501/4968 [12:06<05:08,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6645352840423584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3602/4968 [12:27<04:48,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5557405948638916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 3702/4968 [12:48<04:16,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.653459370136261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3802/4968 [13:09<03:56,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.704559326171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 3902/4968 [13:30<03:39,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.807232677936554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 4001/4968 [13:50<03:16,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.6219663619995117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 4102/4968 [14:12<02:55,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6866225004196167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 4202/4968 [14:32<02:35,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9220677018165588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 4302/4968 [14:53<02:16,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4691568613052368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 4401/4968 [15:14<02:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.0498337745666504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 4501/4968 [15:35<01:36,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7209762930870056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 4602/4968 [15:57<01:16,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6259484887123108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 4701/4968 [16:18<00:56,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6757475137710571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 4801/4968 [16:38<00:36,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6350441575050354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 4901/4968 [16:59<00:13,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.083783149719238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4968/4968 [17:13<00:00,  4.81it/s]\n",
      "  0%|          | 2/4968 [00:00<16:22,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.0201770067214966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 102/4968 [00:21<16:15,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.79212886095047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 202/4968 [00:41<16:24,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.8328093886375427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 302/4968 [01:02<15:51,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.7953106760978699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 401/4968 [01:22<15:33,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.5379353165626526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 501/4968 [01:43<15:08,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.5466597080230713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 601/4968 [02:04<14:53,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.5423016548156738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 702/4968 [02:25<14:45,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.5826029777526855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 801/4968 [02:45<14:13,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.495030403137207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 902/4968 [03:06<14:29,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6069523692131042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1001/4968 [03:27<14:23,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.383100301027298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1102/4968 [03:48<13:08,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.5267592072486877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1201/4968 [04:08<13:20,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.672534704208374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1301/4968 [04:30<13:53,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.5034573078155518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1401/4968 [04:51<12:07,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.7131563425064087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1502/4968 [05:11<11:21,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.8295085430145264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1601/4968 [05:31<11:13,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.5404986143112183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1702/4968 [05:51<10:58,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.1308797597885132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 1802/4968 [06:11<10:33,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.4906623065471649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1902/4968 [06:31<11:19,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.4814990162849426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/4968 [06:52<09:50,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6353176832199097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2102/4968 [07:12<09:47,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 3.388422727584839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 2201/4968 [07:33<09:54,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.549014151096344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 2302/4968 [07:54<08:59,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.44392502307891846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2401/4968 [08:15<09:22,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.5943266153335571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2502/4968 [08:36<08:21,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6889333128929138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2602/4968 [08:57<07:39,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.3956809341907501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 2701/4968 [09:17<07:48,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.866665005683899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 2801/4968 [09:39<07:21,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.4642089605331421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2902/4968 [10:00<07:24,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 2.2739977836608887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 2941/4968 [10:08<06:59,  4.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[227], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m edge_indices \u001b[38;5;241m=\u001b[39m edge_indices\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     22\u001b[0m edge_attrs \u001b[38;5;241m=\u001b[39m edge_attrs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 24\u001b[0m edge_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(edge_predictions, y)\n\u001b[0;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[225], line 35\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, x, edge_indices, edge_attrs)\u001b[0m\n\u001b[0;32m     33\u001b[0m src_embedds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m---> 35\u001b[0m     src_embedds\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_indices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     36\u001b[0m src_embedds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(src_embedds)\n\u001b[0;32m     37\u001b[0m trg_embedds \u001b[38;5;241m=\u001b[39m src_embedds[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[219], line 25\u001b[0m, in \u001b[0;36mGNNEncoder.forward\u001b[1;34m(self, x, edge_indices, edge_attrs)\u001b[0m\n\u001b[0;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[1;32m---> 25\u001b[0m nodes_embedds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m nodes_embedds \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(nodes_embedds, negative_slope\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nodes_embedds\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:302\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[1;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[0;32m    298\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_updater(edge_index, x\u001b[38;5;241m=\u001b[39m(x_l, x_r),\n\u001b[0;32m    299\u001b[0m                           edge_attr\u001b[38;5;241m=\u001b[39medge_attr)\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: PairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_r\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcat:\n\u001b[0;32m    305\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels)\n",
      "File \u001b[1;32m~\\.cache\\pyg\\message_passing\\torch_geometric.nn.conv.gatv2_conv_GATv2Conv_propagate.py:135\u001b[0m, in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, x, alpha, size)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage_and_aggregate\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not implemented\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[1;32m~\\.cache\\pyg\\message_passing\\torch_geometric.nn.conv.gatv2_conv_GATv2Conv_propagate.py:78\u001b[0m, in \u001b[0;36mcollect\u001b[1;34m(self, edge_index, x, alpha, size)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_x_0, Tensor):\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, \u001b[38;5;241m0\u001b[39m, _x_0)\n\u001b[1;32m---> 78\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_x_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:300\u001b[0m, in \u001b[0;36mMessagePassing._index_select\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim, index)\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:304\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_index_select_safe\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: Tensor, index: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    window = 24 * 7\n",
    "    for m in tqdm(range(window, len(snapshots))):\n",
    "        history = snapshots[m - window : m]\n",
    "        y = snapshots[m].y.view(-1)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = [data.x for data in history]\n",
    "        edge_indices = [data.edge_index for data in history]\n",
    "        edge_attrs = [data.edge_attr for data in history]\n",
    "\n",
    "        x = torch.stack(x)\n",
    "        edge_indices = torch.stack(edge_indices)\n",
    "        edge_attrs = torch.stack(edge_attrs)\n",
    "        y = y.to(device)\n",
    "\n",
    "        x = x.to(device)\n",
    "        edge_indices = edge_indices.to(device)\n",
    "        edge_attrs = edge_attrs.to(device)\n",
    "\n",
    "        edge_predictions = model(x, edge_indices, edge_attrs)\n",
    "\n",
    "        loss = F.mse_loss(edge_predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (m - window) % 100 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "euics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
