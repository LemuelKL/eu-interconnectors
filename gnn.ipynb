{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook converts tabular data to graph data for pytorch geometric to ingest.\n",
    "\n",
    "The final graph is a static homogeneous directed graph with temporal signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn import BatchNorm1d\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_df = pd.read_csv(\"data/flow/_combined.csv\")\n",
    "dap_df = pd.read_csv(\"data/dap/_combined.csv\")\n",
    "flow_df.set_index(\"datetime\", inplace=True)\n",
    "dap_df.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "datetime_intersect = flow_df.index.intersection(dap_df.index)\n",
    "flow_df = flow_df.loc[datetime_intersect]\n",
    "dap_df = dap_df.loc[datetime_intersect]\n",
    "\n",
    "# Remove columns that contains \"UK\" or \"IE\"\n",
    "flow_df = flow_df.loc[\n",
    "    :, ~flow_df.columns.str.contains(\"UK\") & ~flow_df.columns.str.contains(\"IE\")\n",
    "]\n",
    "dap_df = dap_df.loc[\n",
    "    :, ~dap_df.columns.str.contains(\"UK\") & ~dap_df.columns.str.contains(\"IE\")\n",
    "]\n",
    "\n",
    "# print(flow_df.isnull().sum())\n",
    "# print(dap_df.isnull().sum())\n",
    "assert not flow_df.isnull().values.any()\n",
    "assert not dap_df.isnull().values.any()\n",
    "dap_df = dap_df.reindex(sorted(dap_df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "# is this good enough?\n",
    "flow_df = (flow_df - flow_df.mean()) / flow_df.std()\n",
    "dap_df = (dap_df - dap_df.mean()) / dap_df.std()\n",
    "\n",
    "# print(flow_df.head())\n",
    "# print(dap_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 45)\n",
      "[['BE' 'BE' 'BE' 'DE' 'DE' 'DE' 'DE' 'DE' 'DE' 'DE']\n",
      " ['FR' 'LU' 'NL' 'BE' 'DK' 'AT' 'CH' 'CZ' 'FR' 'LU']]\n"
     ]
    }
   ],
   "source": [
    "# Static edges of shape (2, n_edges)\n",
    "interconnectors = flow_df.columns[1:]\n",
    "exporters = []\n",
    "importers = []\n",
    "for ic in interconnectors:\n",
    "    exporter, importer = ic.split(\"->\")\n",
    "    exporters.append(exporter)\n",
    "    importers.append(importer)\n",
    "\n",
    "exporters = np.array(exporters)\n",
    "importers = np.array(importers)\n",
    "\n",
    "edges = np.vstack([exporters, importers])\n",
    "print(edges.shape)\n",
    "print(edges[:, :10])\n",
    "n_edges = edges.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5136, 2, 45)\n"
     ]
    }
   ],
   "source": [
    "# Map edge names to indices\n",
    "edge_names = np.unique(edges)\n",
    "edge_map = {edge: i for i, edge in enumerate(edge_names)}\n",
    "edge_indices = np.array([edge_map[edge] for edge in edges.flatten()]).reshape(\n",
    "    edges.shape\n",
    ")\n",
    "# Repeat edge indices for each datetime\n",
    "edge_indices = np.repeat(\n",
    "    edge_indices[np.newaxis, :, :],\n",
    "    len(datetime_intersect),\n",
    "    axis=0,\n",
    ")\n",
    "print(edge_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5136, 45, 1)\n"
     ]
    }
   ],
   "source": [
    "# Edge labels (flow) of shape (n_datetimes, n_edges, 1)\n",
    "edge_labels = np.array(flow_df[interconnectors])\n",
    "edge_labels = np.reshape(edge_labels, (edge_labels.shape[0], edge_labels.shape[1], 1))\n",
    "print(edge_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5136, 45, 1)\n"
     ]
    }
   ],
   "source": [
    "# Edge attributes (capacity, etc.) of shape (n_datetimes, n_edges, n_attributes)\n",
    "# copy the edge labels to the edge attributes\n",
    "edge_attributes = np.copy(edge_labels)\n",
    "# hard code the edge attributes to be ones for now\n",
    "edge_attributes = np.ones(edge_labels.shape)\n",
    "print(edge_attributes.shape)\n",
    "# print(edge_attributes[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5136, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "# Node features (dap)\n",
    "node_features = np.array(dap_df)\n",
    "node_features = np.array(node_features)\n",
    "node_features = np.reshape(\n",
    "\n",
    "    node_features, (node_features.shape[0], node_features.shape[1], 1)\n",
    ")\n",
    "\n",
    "print(node_features.shape)\n",
    "\n",
    "n_nodes = node_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge indices: (2, 45)\n",
      "Edge attributes: (45, 1)\n",
      "Edge labels: (45, 1)\n",
      "Node features: (15, 1)\n"
     ]
    }
   ],
   "source": [
    "assert (\n",
    "    len(datetime_intersect)\n",
    "    == edge_indices.shape[0]\n",
    "    == edge_attributes.shape[0]\n",
    "    == edge_labels.shape[0]\n",
    "    == node_features.shape[0]\n",
    ")\n",
    "# Print a snapshot of the shape of the graph data\n",
    "i = 256\n",
    "print(\"Edge indices:\", edge_indices[i].shape)\n",
    "print(\"Edge attributes:\", edge_attributes[i].shape)\n",
    "print(\"Edge labels:\", edge_labels[i].shape)\n",
    "print(\"Node features:\", node_features[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[15, 1], edge_index=[2, 45], edge_attr=[45, 1], y=[45, 1])\n"
     ]
    }
   ],
   "source": [
    "n_snapshots = len(datetime_intersect)\n",
    "snapshots = []\n",
    "for i in range(n_snapshots):\n",
    "    data = Data(\n",
    "        x=torch.tensor(node_features[i], dtype=torch.float),\n",
    "        edge_index=torch.tensor(edge_indices[i], dtype=torch.long),\n",
    "        edge_attr=torch.tensor(edge_attributes[i], dtype=torch.float),\n",
    "        y=torch.tensor(edge_labels[i], dtype=torch.float),\n",
    "    )\n",
    "    snapshots.append(data)\n",
    "print(snapshots[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GATv2Conv.html\n",
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, hidden_channels, num_heads_GAT, dropout_p_GAT, edge_dim_GAT, momentum_GAT\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.gat = GATv2Conv(\n",
    "            (-1, -1),\n",
    "            hidden_channels,\n",
    "            add_self_loops=False,\n",
    "            heads=num_heads_GAT,\n",
    "            edge_dim=edge_dim_GAT,\n",
    "        )\n",
    "        self.norm = BatchNorm1d(\n",
    "            hidden_channels,\n",
    "            momentum=momentum_GAT,\n",
    "            affine=False,\n",
    "            track_running_stats=False,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_p_GAT)\n",
    "\n",
    "    def forward(self, x, edge_indices, edge_attrs):\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm(x)\n",
    "        nodes_embedds = self.gat(x, edge_indices, edge_attrs)\n",
    "        nodes_embedds = F.leaky_relu(nodes_embedds, negative_slope=0.1)\n",
    "        return nodes_embedds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based module for creating temporal node embeddings.\n",
    "\n",
    "    Args:\n",
    "        dim_model (int): The dimension of the model's hidden states.\n",
    "        num_heads_TR (int): The number of attention heads.\n",
    "        num_encoder_layers_TR (int): The number of encoder layers.\n",
    "        num_decoder_layers_TR (int): The number of decoder layers.\n",
    "        dropout_p_TR (float): Dropout probability.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_model,\n",
    "        num_heads_TR,\n",
    "        num_encoder_layers_TR,\n",
    "        num_decoder_layers_TR,\n",
    "        dropout_p_TR,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pos_encoder = PositionalEncoding(dim_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=dim_model,\n",
    "            nhead=num_heads_TR,\n",
    "            num_decoder_layers=num_encoder_layers_TR,\n",
    "            num_encoder_layers=num_decoder_layers_TR,\n",
    "            dropout=dropout_p_TR,\n",
    "        )\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src = self.pos_encoder(src)\n",
    "        trg = self.pos_encoder(trg)\n",
    "        temporal_node_embeddings = self.transformer(src, trg)\n",
    "        return temporal_node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeDecoder(nn.Module):\n",
    "    def __init__(self, hidden_channels, num_heads_GAT, num_edges, num_nodes):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(\n",
    "            num_nodes * hidden_channels * num_heads_GAT, hidden_channels\n",
    "        )\n",
    "        self.lin2 = nn.Linear(hidden_channels, num_edges)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the tensor\n",
    "        x = torch.flatten(x)\n",
    "        x = self.lin1(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.1)\n",
    "        x = self.lin2(x)\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels,\n",
    "        num_heads_GAT,\n",
    "        dropout_p_GAT,\n",
    "        edge_dim_GAT,\n",
    "        momentum_GAT,\n",
    "        dim_model,\n",
    "        num_heads_TR,\n",
    "        num_encoder_layers_TR,\n",
    "        num_decoder_layers_TR,\n",
    "        dropout_p_TR,\n",
    "        n_edges,\n",
    "        n_nodes,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(\n",
    "            hidden_channels, num_heads_GAT, dropout_p_GAT, edge_dim_GAT, momentum_GAT\n",
    "        )\n",
    "        self.transformer = Transformer(\n",
    "            dim_model,\n",
    "            num_heads_TR,\n",
    "            num_encoder_layers_TR,\n",
    "            num_decoder_layers_TR,\n",
    "            dropout_p_TR,\n",
    "        )\n",
    "        self.decoder = EdgeDecoder(hidden_channels, num_heads_GAT, n_edges, n_nodes)\n",
    "\n",
    "    def forward(self, x, edge_indices, edge_attrs):\n",
    "        src_embedds = []\n",
    "        for i in range(x.shape[0]):\n",
    "            src_embedds.append(self.encoder(x[i], edge_indices[i], edge_attrs[i]))\n",
    "        src_embedds = torch.stack(src_embedds)\n",
    "        trg_embedds = src_embedds[-1].unsqueeze(0)\n",
    "        temporal_node_embedds = self.transformer(src_embedds, trg_embedds)\n",
    "        temporal_node_embedds = temporal_node_embedds.squeeze(0)\n",
    "        edge_predictions = self.decoder(temporal_node_embedds)\n",
    "        return edge_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model(\n",
    "    hidden_channels=8,\n",
    "    num_heads_GAT=2,\n",
    "    dropout_p_GAT=0.1,\n",
    "    edge_dim_GAT=1,  # edge attributes\n",
    "    momentum_GAT=0.1,\n",
    "    dim_model=hidden_channels * num_heads_GAT,\n",
    "    num_heads_TR=2,\n",
    "    num_encoder_layers_TR=2,\n",
    "    num_decoder_layers_TR=2,\n",
    "    dropout_p_TR=0.1,\n",
    "    n_edges=n_edges,\n",
    "    n_nodes=n_nodes,\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/4968 [00:00<18:15,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0799682140350342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 25/4968 [00:05<16:35,  4.96it/s]"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    window = 24 * 7\n",
    "    for m in tqdm(range(window, len(snapshots))):\n",
    "        history = snapshots[m - window : m]\n",
    "        y = snapshots[m].y.view(-1)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = [data.x for data in history]\n",
    "        edge_indices = [data.edge_index for data in history]\n",
    "        edge_attrs = [data.edge_attr for data in history]\n",
    "\n",
    "        x = torch.stack(x)\n",
    "        edge_indices = torch.stack(edge_indices)\n",
    "        edge_attrs = torch.stack(edge_attrs)\n",
    "        y = y.to(device)\n",
    "\n",
    "        x = x.to(device)\n",
    "        edge_indices = edge_indices.to(device)\n",
    "        edge_attrs = edge_attrs.to(device)\n",
    "\n",
    "        edge_predictions = model(x, edge_indices, edge_attrs)\n",
    "\n",
    "        loss = F.mse_loss(edge_predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (m - window) % 100 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "euics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
